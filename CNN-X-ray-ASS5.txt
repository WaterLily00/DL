5 Build image classification model using CNN on pneumonia X RAY IMAGE
dataset.,

code :- 


import numpy as np                                                           #numerical computations
import matplotlib.pyplot as plt                                              #plotting training curves and images.
from tensorflow.keras.models import Sequential                               #Keras container to build a linear stack of layers.
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense     #layers used to build the CNN
from tensorflow.keras.preprocessing.image import ImageDataGenerator          #loads images from folder, rescales and optionally augments them on the fly.

# PATHS — 

train_dir = r"C:\Users\natas\Downloads\Pneumonia X Ray-20221031T100017Z-001\Pneumonia X Ray\train"
test_dir  = r"C:\Users\natas\Downloads\Pneumonia X Ray-20221031T100017Z-001\Pneumonia X Ray\test"

# ------------------------------------------------------------
# 1️⃣ DATA PREPROCESSING — IMAGE GENERATORS
# ------------------------------------------------------------
# ImageDataGenerator automatically loads, rescales, and augments images.
# - rescale=1/255 converts pixel values from [0,255] → [0,1] (faster training)
# - rotation_range, zoom_range, horizontal_flip randomly alter images for variety.
# This improves model generalization and reduces overfitting.

train_gen = ImageDataGenerator(
    rescale=1/255.0,
    rotation_range=20,
    zoom_range=0.2,
    horizontal_flip=True
).flow_from_directory(
    train_dir,
    target_size=(150, 150),  # resize all images to 150×150
    batch_size=32,
    class_mode='binary'      # because we have two classes: 0 (Normal), 1 (Pneumonia)
)

# The test generator only rescales — no augmentation (for fair evaluation).
test_gen = ImageDataGenerator(rescale=1/255.0).flow_from_directory(
    test_dir,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary',
    shuffle=False
)

# ------------------------------------------------------------
# 2️⃣ MODEL ARCHITECTURE — CONVOLUTIONAL NEURAL NETWORK (CNN)
# ------------------------------------------------------------
# CNN automatically learns spatial features like edges, textures, and shapes.
# Layers:
#   Conv2D → applies filters to extract features.
#   MaxPooling2D → reduces spatial dimensions, keeps important info.
#   Flatten → converts feature maps to 1D vector.
#   Dense → fully connected layers for classification.
#   Sigmoid → outputs probability between 0 and 1 for binary classification.


model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),
    MaxPooling2D((2, 2)),

    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D((2, 2)),

    Flatten(),
    Dense(128, activation='relu'),
    Dense(1, activation='sigmoid')   # binary output: 0 or 1
])

# ------------------------------------------------------------
# 3️⃣ COMPILATION STEP
# ------------------------------------------------------------
# - optimizer='adam' → adaptive learning optimizer (best default choice)
# - loss='binary_crossentropy' → measures prediction error for binary classification
# - metrics=['accuracy'] → track model performance during training
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# ------------------------------------------------------------
# 4️⃣ TRAINING THE MODEL
# ------------------------------------------------------------
# model.fit() trains the CNN using training images in small batches.
# Each epoch = one full pass over training data.
# validation_data=test_gen → evaluates performance after each epoch.
# In real projects, use a separate validation folder instead of test set.
history = model.fit(train_gen, epochs=5, validation_data=test_gen, verbose=1)

# ------------------------------------------------------------
# 5️⃣ PLOT TRAINING RESULTS
# ------------------------------------------------------------
# Shows training vs validation accuracy across epochs.
# If training accuracy is much higher than validation accuracy → overfitting.
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# ------------------------------------------------------------
# 6️⃣ PREDICTION & VISUALIZATION
# ------------------------------------------------------------
# Display the model’s predictions on 10 test images.
# model.predict() → gives probability; >0.5 = Pneumonia, <0.5 = Normal.
x_batch, y_batch = next(test_gen)
y_pred = (model.predict(x_batch[:10]) > 0.5).astype(int).reshape(-1)

plt.figure(figsize=(12, 4))
classes = ['Normal', 'Pneumonia']

for i in range(10):
    plt.subplot(2, 5, i + 1)
    plt.imshow(x_batch[i])  # images are already rescaled
    plt.title(f"P:{classes[y_pred[i]]}\nT:{classes[int(y_batch[i])]}")
    plt.axis('off')

plt.tight_layout()
plt.show()



 THEORY SUMMARY (for notes) :- 

# CNN Architecture Summary:
 Image → Conv2D → ReLU → Pooling → Conv2D → Pooling → Flatten → Dense → Output
 - Conv2D extracts spatial features.
 - MaxPooling2D reduces size and complexity.
 - Flatten converts 2D maps to 1D vector.
 - Dense combines features to make prediction.
 - Sigmoid gives probability (Normal vs Pneumonia).

# Formula for convolution:
 Z(i,j) = Σ_m Σ_n (Input(i+m, j+n) × Kernel(m,n)) + bias
 Activation: A = f(Z) = max(0, Z) for ReLU
 Output (sigmoid): σ(z) = 1 / (1 + e^-z)

# Loss function (Binary Cross-Entropy):
 L = -[y*log(p) + (1-y)*log(1-p)]
 where y = true label, p = predicted probability.



# Why each block is needed (one-line reasons)

* Data generator:                   avoids loading all images at once; augments and rescales on the fly.
* Conv2D + MaxPooling:              learn spatial features (edges, textures) and reduce spatial size.
* Flatten + Dense:                  map learned features to final classification decision.
* Sigmoid + binary_crossentropy:    suitable for two-class problems.
* Fit + history:                    trains the model and stores metrics for plotting.
* Predict + visualization:          quick qualitative check of model predictions.


---

