5 Build image classification model using CNN on pneumonia X RAY IMAGE
dataset.,

code :- 

import numpy as np
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt

train_dir = r"C:\Users\ASUS\Downloads\Pneumonia X Ray-20221031T100017Z-001\Pneumonia X Ray\train"
test_dir = r"C:\Users\ASUS\Downloads\Pneumonia X Ray-20221031T100017Z-001\Pneumonia X Ray\test"

train_datagen = ImageDataGenerator(
    shear_range = 0.2,
    height_shift_range = 0.2,
    width_shift_range = 0.2,
    horizontal_flip = True,
    rotation_range = 20,
    rescale = 1/255,
    fill_mode = 'nearest',
    zoom_range = 0.2   
)
#shhrrwfz

test_datagen = ImageDataGenerator(rescale =1./255)

#(dir_name, t_size,b_size,c_binary)
train_gen = train_datagen.flow_from_directory(train_dir, target_size=(150,150), batch_size = 128, class_mode='binary')
test_gen = test_datagen.flow_from_directory(test_dir, target_size=(150,150), batch_size = 128, class_mode='binary')


model =  Sequential([
    Conv2D(32,(3,3),activation='relu', input_shape=(150,150,3)),
    MaxPooling2D(2,2),

    Conv2D(32,(3,3),activation='relu'),
    MaxPooling2D(2,2),

    Conv2D(32,(3,3),activation='relu'),
    MaxPooling2D(2,2),

    Flatten(),
    Dense(128, activation='relu'),
    Dense(1,activation='sigmoid'),
])

#compile
model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy'])


#history
history = model.fit(train_gen, epochs=10, batch_size=128, validation_data=test_gen)



plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()


predictions = model.predict(test_gen)



x_test, y_true = next(test_gen)
# Predict on the first image
y_pred = model.predict(x_test[:45])
#logic
y_pred_label = int(y_pred[0] > 0.5)
class_names = ['Normal', 'Pneumonia']

plt.imshow(x_test[0])
plt.title(f"Pred: {class_names[y_pred_label]}\nTrue: {class_names[int(y_true[0])]}")
plt.axis('off')
plt.show()




**** THEORY SUMMARY (for notes) :- 

#  MODEL ARCHITECTURE — CONVOLUTIONAL NEURAL NETWORK (CNN)

# CNN automatically learns spatial features like edges, textures, and shapes.
# Layers:
#   Conv2D → applies filters to extract features.
#   MaxPooling2D → reduces spatial dimensions, keeps important info.
#   Flatten → converts feature maps to 1D vector.
#   Dense → fully connected layers for classification.
#   Sigmoid → outputs probability between 0 and 1 for binary classification.

# - optimizer='adam' → adaptive learning optimizer (best default choice)
# - loss='binary_crossentropy' → measures prediction error for binary classification
# - metrics=['accuracy'] → track model performance during training

# model.fit() trains the CNN using training images in small batches.
# Each epoch = one full pass over training data.
# validation_data=test_gen → evaluates performance after each epoch.
# In real projects, use a separate validation folder instead of test set.

# Shows training vs validation accuracy across epochs.
# If training accuracy is much higher than validation accuracy → overfitting.


# CNN Architecture Summary:
 Image → Conv2D → ReLU → Pooling → Conv2D → Pooling → Flatten → Dense → Output
 - Conv2D extracts spatial features.
 - MaxPooling2D reduces size and complexity.
 - Flatten converts 2D maps to 1D vector.
 - Dense combines features to make prediction.
 - Sigmoid gives probability (Normal vs Pneumonia).

# Formula for convolution:
 Z(i,j) = Σ_m Σ_n (Input(i+m, j+n) × Kernel(m,n)) + bias
 Activation: A = f(Z) = max(0, Z) for ReLU
 Output (sigmoid): σ(z) = 1 / (1 + e^-z)

# Loss function (Binary Cross-Entropy):
 L = -[y*log(p) + (1-y)*log(1-p)]
 where y = true label, p = predicted probability.



# Why each block is needed (one-line reasons)

* Data generator:                   avoids loading all images at once; augments and rescales on the fly.
* Conv2D + MaxPooling:              learn spatial features (edges, textures) and reduce spatial size.
* Flatten + Dense:                  map learned features to final classification decision.
* Sigmoid + binary_crossentropy:    suitable for two-class problems.
* Fit + history:                    trains the model and stores metrics for plotting.
* Predict + visualization:          quick qualitative check of model predictions.


---


